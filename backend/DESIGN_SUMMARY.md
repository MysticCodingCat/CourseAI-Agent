# CourseAI 設計總結
## 給評審看的版本

---

## 一句話總結

**我們利用 AMD MI300X 的大記憶體，打造了一個能在課堂期間追蹤每位學生學習歷程的個人化 AI 教學助手。**

---

## 核心創新

### 1. 教育科學基礎

我們的系統基於認知科學研究：

- **測試效果**（Karpicke & Roediger, 2008）：測試比重複閱讀有效 2.2 倍
- **遺忘曲線**（Ebbinghaus）：實作 SuperMemo 間隔重複算法
- **遷移學習**：用 GraphRAG 測試學生是否真正理解概念

### 2. 技術實作

```
學生答題
  ↓
系統即時分析（4-5 次 LLM 推理）：
  1. 評分（0-5 分）
  2. 錯誤診斷（找出迷思概念）
  3. 個性化回饋（蘇格拉底式引導）
  4. 更新記憶強度（遺忘曲線計算）
  5. 推薦下一步（根據記憶狀態）
  ↓
2 秒內完成
```

---

## MI300X 的角色

### 問題：為什麼需要大記憶體？

**傳統方案的瓶頸**：
```
學生 A 答題 → 從硬碟讀取學生 A 資料（100ms）→ 處理 → 寫回硬碟（50ms）
學生 B 答題 → 從硬碟讀取學生 B 資料（100ms）→ 處理 → 寫回硬碟（50ms）
...
50 位學生同時答題 → 硬碟 I/O 成為瓶頸
```

**我們的方案**：
```
課程開始
  ↓
一次性載入所有資料到記憶體（1 秒）
  - GraphRAG 索引：600 MB
  - 50 位學生資料：3.5 MB
  ↓
課程進行中（2 小時）
  - 所有查詢從記憶體讀取（1ms）
  - 快 100 倍
  ↓
課程結束
  ↓
一次性寫回硬碟（1 秒）
```

### 實際使用

- **使用量**：約 604 MB（不到 1GB）
- **MI300X 容量**：192 GB
- **使用率**：0.3%

**不是「用滿」，而是「足夠大」**：
- 小記憶體 GPU（24GB）：裝不下模型 + GraphRAG + 學生資料
- MI300X（192GB）：全部裝得下，還有餘裕

### MI300X 的具體優勢

1. **大容量（192GB HBM3）**：模型（50GB）+ GraphRAG（600MB）+ 學生資料（3.5MB）同時載入
2. **統一記憶體架構**：GPU 推理引擎直接存取學生資料，無需 CPU-GPU 複製
3. **高頻寬（5.3 TB/s）**：支援 50 位學生並行查詢
4. **CDNA 3 架構**：針對 AI 推論優化，加速 LLM（GPT-OSS-120B）與嵌入模型推論
5. **ROCm 生態支援**：完全相容 PyTorch、Hugging Face，程式碼不需修改

---

## 系統架構

```
┌─────────────────────────────────────┐
│  系統記憶體（RAM）                   │
│  • GraphRAG 索引（600MB）           │
│  • 學生追蹤資料（3.5MB）            │
└─────────────────────────────────────┘
              ↕
        （需要時傳輸）
              ↕
┌─────────────────────────────────────┐
│  AMD MI300X (192GB HBM3)            │
│  • GPT-OSS-120B 模型（50GB）        │
│  • vLLM 推理引擎（30GB）            │
└─────────────────────────────────────┘
```

**澄清**：
- 學生資料存在系統 RAM，不是 GPU 記憶體
- GPU 只負責推理，不儲存學生資料
- MI300X 的統一記憶體架構讓 GPU 能直接存取 RAM

---

## 技術細節

### 檔案結構

已實作的核心模組：

1. **`student_memory.py`** - 學生記憶追蹤
   - SuperMemo SM-2 算法
   - 遺忘曲線計算
   - 記憶強度追蹤

2. **`adaptive_quiz.py`** - 智慧題目生成
   - 4 種題型（回憶、應用、關聯、錯誤診斷）
   - 根據記憶強度調整難度

3. **`realtime_analytics.py`** - 實時學習分析
   - 即時評分與錯誤診斷
   - 蘇格拉底式回饋生成
   - 個人化學習推薦

4. **`session_manager.py`** - 會話管理
   - 課程開始時載入資料
   - 課程結束時儲存並清空

5. **`rag_engine.py`** - GraphRAG 引擎
   - FAISS 向量檢索
   - NetworkX 知識圖譜
   - 混合檢索（向量 + 圖譜）

### 資料流程

```python
# 課程開始
session = CourseSession(
    course_id="deep_learning",
    student_ids=["student_001", "student_002", ...]
)
session.start_session(pdf_path="lecture.pdf")

# 課程進行中
for student_answer in answers:
    # 實時分析（高頻推理）
    result = analytics.analyze_answer(question, answer)
    # 包含：評分、錯誤診斷、回饋、記憶更新、推薦

# 課程結束
session.end_session()  # 儲存並清空記憶體
```

---

## 評審問答準備

### Q1: 你們如何利用 MI300X？

**A**: 我們設計了課堂級的個人化學習系統。在 2 小時課程期間，將 50 位學生的學習歷程和 GraphRAG 索引載入記憶體，查詢速度從 100ms 降至 1ms。

我們充分利用了 MI300X 的三個特性：
1. **192GB 大容量**：同時載入模型、GraphRAG、學生資料
2. **CDNA 3 架構**：我們需要高頻 LLM 推論（每次答題 4-5 次），CDNA 3 的 AI 推論優化確保低延遲
3. **ROCm 生態**：我們使用 vLLM、PyTorch、Hugging Face，完全相容 ROCm，程式碼不需修改

### Q2: 你們用了多少記憶體？

**A**: 單堂課約 604 MB（GraphRAG 600MB + 50 位學生 3.5MB）。雖然沒用滿 192GB，但需要大容量才能同時載入模型（50GB）、推理快取（30GB）和課程資料。

### Q3: 為什麼不用商業 API？

**A**: （不主動提）如果被問到，回答：我們的設計需要維持「課堂狀態」，追蹤每位學生的長期學習歷程。這需要在課程期間持續存取學生資料，而商業 API 每次請求都是獨立的，無法維持狀態。另外，比賽鼓勵使用 AMD 平台展示硬體能力。

### Q4: 你們的創新點是什麼？

**A**:
1. **教育科學基礎**：基於認知科學研究（測試效果、遺忘曲線）設計學習流程
2. **個人化追蹤**：每位學生有獨立的記憶追蹤器，實作 SuperMemo 間隔重複算法
3. **GraphRAG**：結合向量檢索與知識圖譜，測試概念遷移能力
4. **實時多階段分析**：每次答題進行 4-5 次 LLM 推理，提供即時個性化回饋

### Q5: 這個設計可以規模化嗎？

**A**: 可以。單堂課只用 604 MB，MI300X 可以支援多堂課並行。更重要的是，我們用「會話」管理資料生命週期，課程結束後資料寫回硬碟並清空記憶體，不會永久占用。

---

## Demo 展示重點

### 展示流程（3-5 分鐘）

1. **啟動課堂會話**（10 秒）
   ```
   顯示：載入 GraphRAG 索引（600MB）
   顯示：載入 3 位學生資料
   ```

2. **學生 A 答題**（30 秒）
   ```
   問題："什麼是卷積神經網路？"
   學生答："CNN 是用來處理影像的"

   系統即時分析：
   - 評分：3/5（基本正確但不完整）
   - 錯誤診斷：遺漏「自動特徵提取」概念
   - 回饋："你提到了影像處理，但 CNN 還有一個重要特性..."
   - 記憶強度：0.3 → 0.5
   - 推薦：繼續練習應用題
   ```

3. **查看記憶追蹤**（20 秒）
   ```
   顯示學生 A 的知識圖譜：
   - CNN：記憶強度 0.5（黃色）
   - 反向傳播：記憶強度 0.2（紅色，需複習）
   - Dropout：記憶強度 0.8（綠色，已掌握）
   ```

4. **GraphRAG 展示**（30 秒）
   ```
   查詢："過擬合"

   向量檢索：找到相關段落（Dropout、L2 正則化）
   圖譜檢索：找到關聯概念（早停、資料增強）

   展示知識圖譜視覺化
   ```

5. **結束課堂會話**（10 秒）
   ```
   顯示：儲存 3 位學生資料到硬碟
   顯示：記憶體已清空
   ```

### 強調的點

1. ✅ **速度**：查詢 1ms（顯示時間戳）
2. ✅ **個人化**：每位學生有獨立的記憶追蹤
3. ✅ **教育科學**：遺忘曲線、間隔重複
4. ✅ **GraphRAG**：向量 + 圖譜混合檢索

### 不強調的點

1. ❌ 不強調「比商業 API 好」
2. ❌ 不強調「用了多少 GB」
3. ❌ 不過度技術細節

---

## 簡報架構建議

### 投影片 1：標題
CourseAI：基於教育科學的個人化 AI 教學助手

### 投影片 2：問題
學生常見迷思：「讀懂課本 = 學會了」
研究發現：測試比重複閱讀有效 2.2 倍

### 投影片 3：解決方案
個人化記憶追蹤 + 智慧題目生成 + 實時學習分析

### 投影片 4：技術架構
（系統架構圖）
強調：需要大記憶體才能實現課堂級的個人化追蹤

### 投影片 5：MI300X 優勢
1. 大容量：模型 + GraphRAG + 學生資料同時載入
2. 統一記憶體：GPU 直接存取學生資料
3. 高頻寬：支援多學生並行

### 投影片 6：Demo

### 投影片 7：成果與未來
已實作：記憶追蹤、題目生成、實時分析、GraphRAG
未來：視覺化、語音輸入、更多課程

---

## 重點提醒

### ✅ 要強調

1. **教育科學基礎**：認知科學研究支持
2. **個人化學習**：每位學生獨立追蹤
3. **技術創新**：GraphRAG + 記憶追蹤
4. **MI300X 的必要性**：需要大記憶體才能實現

### ❌ 避免

1. ~~過度對比商業 API~~
2. ~~刻意強調「用了多少 GB」~~
3. ~~過度技術細節~~
4. ~~說「資料存在 GPU」~~（應該說系統記憶體）

---

**核心訊息**：我們利用 MI300X 的大記憶體，實現了基於教育科學的個人化學習系統。
